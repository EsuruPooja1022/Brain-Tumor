{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "zYr9qHe77-Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the path to your dataset\n",
        "dataset_path = \"/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/Training\"\n",
        "\n",
        "# Function to sharpen the image\n",
        "def sharpen_image(image):\n",
        "    kernel = np.array([[0, -1, 0],\n",
        "                       [-1, 5, -1],\n",
        "                       [0, -1, 0]])  # Sharpening kernel\n",
        "    sharpened_image = cv2.filter2D(image, -1, kernel)\n",
        "    return sharpened_image\n",
        "\n",
        "# Function to adjust contrast\n",
        "def adjust_contrast(image, alpha=1.5, beta=0):\n",
        "    contrast_adjusted = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
        "    return contrast_adjusted\n",
        "\n",
        "# Function to zoom into the image (crop and resize)\n",
        "def zoom_image(image, zoom_factor=0.8):\n",
        "    height, width = image.shape[:2]\n",
        "    new_h, new_w = int(height * zoom_factor), int(width * zoom_factor)\n",
        "    crop_h, crop_w = (height - new_h) // 2, (width - new_w) // 2\n",
        "    zoomed_image = image[crop_h:crop_h + new_h, crop_w:crop_w + new_w]\n",
        "    zoomed_image = cv2.resize(zoomed_image, (width, height))  # Resize back to original dimensions\n",
        "    return zoomed_image\n",
        "\n",
        "# Function to enhance color using HSV transformation\n",
        "def enhance_color(image):\n",
        "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    hsv_image[:, :, 1] = cv2.add(hsv_image[:, :, 1], 50)  # Increase saturation\n",
        "    enhanced_image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2BGR)\n",
        "    return enhanced_image\n",
        "\n",
        "# Load images and apply variations\n",
        "def process_images_with_variations(dataset_path):\n",
        "    categories = os.listdir(dataset_path)\n",
        "    for category in categories:\n",
        "        category_path = os.path.join(dataset_path, category)\n",
        "        if os.path.isdir(category_path):\n",
        "            print(f\"Processing category: {category}\")\n",
        "            images = os.listdir(category_path)\n",
        "            for i, image_name in enumerate(images[:3]):  # Limit to 3 images per category\n",
        "                image_path = os.path.join(category_path, image_name)\n",
        "                image = cv2.imread(image_path)\n",
        "                if image is None:\n",
        "                    continue\n",
        "\n",
        "                # Resize for uniformity\n",
        "                image = cv2.resize(image, (256, 256))\n",
        "\n",
        "                # Apply variations\n",
        "                sharpened_image = sharpen_image(image)\n",
        "                contrast_image = adjust_contrast(image)\n",
        "                zoomed_image = zoom_image(image)\n",
        "                enhanced_color_image = enhance_color(image)\n",
        "\n",
        "                # Plot and visualize with grid and axis numbers\n",
        "                fig, axs = plt.subplots(1, 5, figsize=(20, 5))\n",
        "                axs[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "                axs[0].set_title(\"Original Image\")\n",
        "                axs[0].set_xticks(np.arange(0, 256, 50))  # Add x-axis numbers\n",
        "                axs[0].set_yticks(np.arange(0, 256, 50))  # Add y-axis numbers\n",
        "                axs[0].grid(color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
        "\n",
        "                axs[1].imshow(cv2.cvtColor(sharpened_image, cv2.COLOR_BGR2RGB))\n",
        "                axs[1].set_title(\"Sharpened\")\n",
        "                axs[1].set_xticks(np.arange(0, 256, 50))\n",
        "                axs[1].set_yticks(np.arange(0, 256, 50))\n",
        "                axs[1].grid(color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
        "\n",
        "                axs[2].imshow(cv2.cvtColor(contrast_image, cv2.COLOR_BGR2RGB))\n",
        "                axs[2].set_title(\"Contrast Adjusted\")\n",
        "                axs[2].set_xticks(np.arange(0, 256, 50))\n",
        "                axs[2].set_yticks(np.arange(0, 256, 50))\n",
        "                axs[2].grid(color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
        "\n",
        "                axs[3].imshow(cv2.cvtColor(zoomed_image, cv2.COLOR_BGR2RGB))\n",
        "                axs[3].set_title(\"Zoomed\")\n",
        "                axs[3].set_xticks(np.arange(0, 256, 50))\n",
        "                axs[3].set_yticks(np.arange(0, 256, 50))\n",
        "                axs[3].grid(color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
        "\n",
        "                axs[4].imshow(cv2.cvtColor(enhanced_color_image, cv2.COLOR_BGR2RGB))\n",
        "                axs[4].set_title(\"Color Enhanced\")\n",
        "                axs[4].set_xticks(np.arange(0, 256, 50))\n",
        "                axs[4].set_yticks(np.arange(0, 256, 50))\n",
        "                axs[4].grid(color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
        "\n",
        "                for ax in axs:\n",
        "                    ax.set_xlabel(\"X-Axis\")  # Add X-axis label\n",
        "                    ax.set_ylabel(\"Y-Axis\")  # Add Y-axis label\n",
        "\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "\n",
        "# Run the process\n",
        "process_images_with_variations(dataset_path)\n"
      ],
      "metadata": {
        "id": "tkOBfzWaUhnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "\n",
        "# Set the path to your dataset\n",
        "dataset_path = \"/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/Training\"\n",
        "\n",
        "# Function to rotate the image randomly\n",
        "def rotate_image(image):\n",
        "    rows, cols = image.shape[:2]\n",
        "    angle = randint(-45, 45)  # Rotate randomly between -45 to 45 degrees\n",
        "    rotation_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
        "    rotated_image = cv2.warpAffine(image, rotation_matrix, (cols, rows))\n",
        "    return rotated_image\n",
        "\n",
        "# Function to apply Gaussian blur\n",
        "def blur_image(image, ksize=(5, 5)):\n",
        "    blurred_image = cv2.GaussianBlur(image, ksize, 0)\n",
        "    return blurred_image\n",
        "\n",
        "# Function to invert colors\n",
        "def invert_colors(image):\n",
        "    inverted_image = cv2.bitwise_not(image)\n",
        "    return inverted_image\n",
        "\n",
        "# Function to flip image horizontally\n",
        "def flip_image(image):\n",
        "    flipped_image = cv2.flip(image, 1)\n",
        "    return flipped_image\n",
        "\n",
        "# Load images and apply variations\n",
        "def process_images(dataset_path):\n",
        "    categories = os.listdir(dataset_path)\n",
        "    for category in categories:\n",
        "        category_path = os.path.join(dataset_path, category)\n",
        "        if os.path.isdir(category_path):\n",
        "            print(f\"Processing category: {category}\")\n",
        "            images = os.listdir(category_path)\n",
        "            for i, image_name in enumerate(images[:3]):  # Limit to 3 images per category\n",
        "                image_path = os.path.join(category_path, image_name)\n",
        "                image = cv2.imread(image_path)\n",
        "                if image is None:\n",
        "                    continue\n",
        "\n",
        "                # Resize for uniformity\n",
        "                image = cv2.resize(image, (256, 256))\n",
        "\n",
        "                # Apply variations\n",
        "                rotated_image = rotate_image(image)\n",
        "                blurred_image = blur_image(image)\n",
        "                inverted_image = invert_colors(image)\n",
        "                flipped_image = flip_image(image)\n",
        "\n",
        "                # Plot and visualize with grid and axis numbers\n",
        "                fig, axs = plt.subplots(1, 5, figsize=(20, 5))\n",
        "                axs[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "                axs[0].set_title(\"Original Image\")\n",
        "                axs[0].set_xticks(np.arange(0, 256, 50))  # Add x-axis numbers\n",
        "                axs[0].set_yticks(np.arange(0, 256, 50))  # Add y-axis numbers\n",
        "                axs[0].grid(color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
        "\n",
        "                axs[1].imshow(cv2.cvtColor(rotated_image, cv2.COLOR_BGR2RGB))\n",
        "                axs[1].set_title(\"Rotated\")\n",
        "                axs[1].set_xticks(np.arange(0, 256, 50))\n",
        "                axs[1].set_yticks(np.arange(0, 256, 50))\n",
        "                axs[1].grid(color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
        "\n",
        "                axs[2].imshow(cv2.cvtColor(blurred_image, cv2.COLOR_BGR2RGB))\n",
        "                axs[2].set_title(\"Blurred\")\n",
        "                axs[2].set_xticks(np.arange(0, 256, 50))\n",
        "                axs[2].set_yticks(np.arange(0, 256, 50))\n",
        "                axs[2].grid(color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
        "\n",
        "                axs[3].imshow(cv2.cvtColor(inverted_image, cv2.COLOR_BGR2RGB))\n",
        "                axs[3].set_title(\"Color Inverted\")\n",
        "                axs[3].set_xticks(np.arange(0, 256, 50))\n",
        "                axs[3].set_yticks(np.arange(0, 256, 50))\n",
        "                axs[3].grid(color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
        "\n",
        "                axs[4].imshow(cv2.cvtColor(flipped_image, cv2.COLOR_BGR2RGB))\n",
        "                axs[4].set_title(\"Horizontally Flipped\")\n",
        "                axs[4].set_xticks(np.arange(0, 256, 50))\n",
        "                axs[4].set_yticks(np.arange(0, 256, 50))\n",
        "                axs[4].grid(color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
        "\n",
        "                for ax in axs:\n",
        "                    ax.set_xlabel(\"X-Axis\")  # Add X-axis label\n",
        "                    ax.set_ylabel(\"Y-Axis\")  # Add Y-axis label\n",
        "\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "\n",
        "# Run the process\n",
        "process_images(dataset_path)\n"
      ],
      "metadata": {
        "id": "QC0o99C27QKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "\n",
        "# Set the path to your dataset\n",
        "dataset_path = \"/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/Training\"\n",
        "\n",
        "# Function to rotate the image randomly\n",
        "def rotate_image(image):\n",
        "    rows, cols = image.shape[:2]\n",
        "    angle = randint(-45, 45)  # Rotate randomly between -45 to 45 degrees\n",
        "    rotation_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
        "    rotated_image = cv2.warpAffine(image, rotation_matrix, (cols, rows))\n",
        "    return rotated_image\n",
        "\n",
        "# Function to apply Gaussian blur\n",
        "def blur_image(image, ksize=(5, 5)):\n",
        "    blurred_image = cv2.GaussianBlur(image, ksize, 0)\n",
        "    return blurred_image\n",
        "\n",
        "# Function to invert colors\n",
        "def invert_colors(image):\n",
        "    inverted_image = cv2.bitwise_not(image)\n",
        "    return inverted_image\n",
        "\n",
        "# Function to flip image horizontally\n",
        "def flip_image(image):\n",
        "    flipped_image = cv2.flip(image, 1)\n",
        "    return flipped_image\n",
        "\n",
        "# Load images and apply variations\n",
        "def process_images(dataset_path):\n",
        "    categories = os.listdir(dataset_path)\n",
        "    for category in categories:\n",
        "        category_path = os.path.join(dataset_path, category)\n",
        "        if os.path.isdir(category_path):\n",
        "            print(f\"Processing category: {category}\")\n",
        "            images = os.listdir(category_path)\n",
        "            for i, image_name in enumerate(images[:3]):  # Limit to 3 images per category\n",
        "                image_path = os.path.join(category_path, image_name)\n",
        "                image = cv2.imread(image_path)\n",
        "                if image is None:\n",
        "                    continue\n",
        "\n",
        "                # Resize for uniformity\n",
        "                image = cv2.resize(image, (256, 256))\n",
        "\n",
        "                # Apply variations\n",
        "                rotated_image = rotate_image(image)\n",
        "                blurred_image = blur_image(image)\n",
        "                inverted_image = invert_colors(image)\n",
        "                flipped_image = flip_image(image)\n",
        "\n",
        "                # Plot and visualize with grid box\n",
        "                fig, axs = plt.subplots(1, 5, figsize=(20, 5))\n",
        "                axs[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "                axs[0].set_title(\"Original Image\")\n",
        "                axs[0].axis(\"off\")\n",
        "\n",
        "                axs[1].imshow(cv2.cvtColor(rotated_image, cv2.COLOR_BGR2RGB))\n",
        "                axs[1].set_title(\"Rotated\")\n",
        "                axs[1].axis(\"off\")\n",
        "\n",
        "                axs[2].imshow(cv2.cvtColor(blurred_image, cv2.COLOR_BGR2RGB))\n",
        "                axs[2].set_title(\"Blurred\")\n",
        "                axs[2].axis(\"off\")\n",
        "\n",
        "                axs[3].imshow(cv2.cvtColor(inverted_image, cv2.COLOR_BGR2RGB))\n",
        "                axs[3].set_title(\"Color Inverted\")\n",
        "                axs[3].axis(\"off\")\n",
        "\n",
        "                axs[4].imshow(cv2.cvtColor(flipped_image, cv2.COLOR_BGR2RGB))\n",
        "                axs[4].set_title(\"Horizontally Flipped\")\n",
        "                axs[4].axis(\"off\")\n",
        "\n",
        "                # Add grid lines\n",
        "                for ax in axs:\n",
        "                    ax.grid(color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
        "\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "\n",
        "# Run the process\n",
        "process_images(dataset_path)\n"
      ],
      "metadata": {
        "id": "o5BBbkgd57b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "\n",
        "# Set the path to your dataset\n",
        "dataset_path = \"/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/Training\"\n",
        "\n",
        "# Function to add bounding boxes\n",
        "def add_bounding_box(image):\n",
        "    height, width = image.shape[:2]\n",
        "    x1, y1 = randint(0, width // 4), randint(0, height // 4)\n",
        "    x2, y2 = randint(3 * width // 4, width), randint(3 * height // 4, height)\n",
        "    image_with_box = image.copy()\n",
        "    color = (0, 255, 0)  # Green box\n",
        "    thickness = 2\n",
        "    cv2.rectangle(image_with_box, (x1, y1), (x2, y2), color, thickness)\n",
        "    return image_with_box\n",
        "\n",
        "# Function to adjust brightness\n",
        "def adjust_brightness(image, value=30):\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    h, s, v = cv2.split(hsv)\n",
        "    v = cv2.add(v, value)\n",
        "    v = np.clip(v, 0, 255)\n",
        "    final_hsv = cv2.merge((h, s, v))\n",
        "    brightened_image = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
        "    return brightened_image\n",
        "\n",
        "# Function to add noise\n",
        "def add_noise(image):\n",
        "    noise = np.random.normal(0, 25, image.shape).astype(np.uint8)\n",
        "    noisy_image = cv2.add(image, noise)\n",
        "    return noisy_image\n",
        "\n",
        "# Load images and apply variations\n",
        "def process_images(dataset_path):\n",
        "    categories = os.listdir(dataset_path)\n",
        "    for category in categories:\n",
        "        category_path = os.path.join(dataset_path, category)\n",
        "        if os.path.isdir(category_path):\n",
        "            print(f\"Processing category: {category}\")\n",
        "            images = os.listdir(category_path)\n",
        "            for i, image_name in enumerate(images[:3]):  # Limit to 3 images per category\n",
        "                image_path = os.path.join(category_path, image_name)\n",
        "                image = cv2.imread(image_path)\n",
        "                if image is None:\n",
        "                    continue\n",
        "\n",
        "                # Resize for uniformity\n",
        "                image = cv2.resize(image, (256, 256))\n",
        "\n",
        "                # Apply variations\n",
        "                image_with_box = add_bounding_box(image)\n",
        "                brightened_image = adjust_brightness(image)\n",
        "                noisy_image = add_noise(image)\n",
        "\n",
        "                # Plot and visualize\n",
        "                fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
        "                axs[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "                axs[0].set_title(\"Original Image\")\n",
        "                axs[0].axis(\"off\")\n",
        "\n",
        "                axs[1].imshow(cv2.cvtColor(image_with_box, cv2.COLOR_BGR2RGB))\n",
        "                axs[1].set_title(\"With Bounding Box\")\n",
        "                axs[1].axis(\"off\")\n",
        "\n",
        "                axs[2].imshow(cv2.cvtColor(brightened_image, cv2.COLOR_BGR2RGB))\n",
        "                axs[2].set_title(\"Brightened\")\n",
        "                axs[2].axis(\"off\")\n",
        "\n",
        "                axs[3].imshow(cv2.cvtColor(noisy_image, cv2.COLOR_BGR2RGB))\n",
        "                axs[3].set_title(\"With Noise\")\n",
        "                axs[3].axis(\"off\")\n",
        "\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "\n",
        "# Run the process\n",
        "process_images(dataset_path)\n"
      ],
      "metadata": {
        "id": "Ey291xIdsQ3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print ('Importing is done')"
      ],
      "metadata": {
        "id": "UEL-rozLghl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds=\"/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/Training\"\n",
        "test_ds=\"/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/Testing\""
      ],
      "metadata": {
        "id": "5fT8-dtxhqIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names= os.listdir('/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/Training')\n",
        "n_classes = len(class_names)\n",
        "print(f\"Total Number of Classes : {n_classes} \\nClass Names : {class_names}\")"
      ],
      "metadata": {
        "id": "OIIC3jCeiDZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "image_size = (224, 224)\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator()\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_ds,target_size= image_size ,batch_size=batch_size,shuffle=True,class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_ds,target_size= image_size ,batch_size=batch_size,shuffle=True,class_mode='categorical')"
      ],
      "metadata": {
        "id": "TH9povXEiF6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=[224, 224, 3]\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\", input_shape=input_shape),\n",
        "    Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "    Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "    Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "    Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256,activation = \"relu\"),\n",
        "    Dense(64,activation = \"relu\"),\n",
        "    Dense(n_classes, activation = \"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])"
      ],
      "metadata": {
        "id": "HuUk4ejKiNbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "m5NeJgzKiQt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10   # number of epochs in training\n",
        "history = model.fit(train_generator, epochs= epochs, verbose= 1, validation_data=test_generator , shuffle= False)"
      ],
      "metadata": {
        "id": "tx4ZoFLhiUdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/Gptmodel/dddriveTUmor.h5')\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/Gptmodel/dddrriveTUmor.keras')"
      ],
      "metadata": {
        "id": "eX5poePViY5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results =pd.DataFrame(history.history)\n",
        "results.tail()"
      ],
      "metadata": {
        "id": "j-AsyGFzv1UG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ttsa2fG7wE7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Train','Val'], loc= 'upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hFqYa007xm2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_score = model.evaluate(train_generator, verbose= 1)\n",
        "test_score = model.evaluate(test_generator, verbose= 1)\n",
        "\n",
        "print(\"Train Loss: \", train_score[0])\n",
        "print(\"Train Accuracy: \", train_score[1])\n",
        "print('-' * 20)\n",
        "print(\"Test Loss: \", test_score[0])\n",
        "print(\"Test Accuracy: \", test_score[1])"
      ],
      "metadata": {
        "id": "g0qni-_axpbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred =model.predict(test_generator)\n",
        "y_pred = np.argmax(y_pred,axis=1)"
      ],
      "metadata": {
        "id": "lCXuzCSGxrWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict('/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/Testing/pituitary/Te-piTr_0000.jpg')"
      ],
      "metadata": {
        "id": "NcwC7UWMzqGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Define the image path\n",
        "image_path = '/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/Testing/pituitary/Te-piTr_0000.jpg'\n",
        "\n",
        "# Load the image using Keras utility functions\n",
        "img = load_img(image_path, target_size=(224, 224))  # Replace (224, 224) with your desired image size\n",
        "\n",
        "# Convert the image to a NumPy array\n",
        "img_array = img_to_array(img)\n",
        "\n",
        "# Add an extra dimension to represent the batch size (as model.predict expects a batch of images)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Preprocess the image (if your model requires specific preprocessing)\n",
        "# For example, you might need to normalize pixel values to the range [0, 1]\n",
        "img_array = img_array / 255.0  # Example normalization\n",
        "\n",
        "# Now, make the prediction\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "# Process the prediction (e.g., get the class with the highest probability)\n",
        "predicted_class = np.argmax(prediction)\n",
        "\n",
        "print(f\"Predicted class: {predicted_class}\")"
      ],
      "metadata": {
        "id": "Bxi5QaAn0Mjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(img_path):\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    from PIL import Image\n",
        "    label = list(class_dict.keys())\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    img = Image.open(img_path)\n",
        "    resized_img = img.resize((299, 299))\n",
        "    img = np.asarray(resized_img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = img / 255\n",
        "    predictions = model.predict(img)\n",
        "    probs = list(predictions[0])\n",
        "    labels = label\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.imshow(resized_img)\n",
        "    plt.subplot(2, 1, 2)\n",
        "    bars = plt.barh(labels, probs)\n",
        "    plt.xlabel('Probability', fontsize=15)\n",
        "    ax = plt.gca()\n",
        "    ax.bar_label(bars, fmt = '%.2f')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "predict('/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/Testing/pituitary/Te-piTr_0000.jpg')"
      ],
      "metadata": {
        "id": "sb6XlyDI0qvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import os\n",
        "\n",
        "# Step 1: Mount Google Drive to access your saved model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Load the model from Google Drive\n",
        "model_path = '/content/drive/MyDrive/Colab Notebooks/Gptmodel/dddriveTUmor.h5'\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "# Step 3: Define class names (order should match your training directory's class order)\n",
        "class_names = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "# Step 4: Preprocess the image\n",
        "def preprocess_image(image_path):\n",
        "    image = load_img(image_path, target_size=(224, 224))  # Load and resize the image\n",
        "    image = img_to_array(image)  # Convert the image to array\n",
        "    image = np.expand_dims(image, axis=0)  # Add a batch dimension\n",
        "    image /= 255.0  # Normalize pixel values to [0, 1]\n",
        "    return image\n",
        "\n",
        "# Step 5: Make a prediction\n",
        "def predict_tumor(image_path):\n",
        "    image = preprocess_image(image_path)  # Preprocess the image\n",
        "    predictions = model.predict(image)  # Get predictions\n",
        "    predicted_class = np.argmax(predictions)  # Find index of highest probability\n",
        "    class_label = class_names[predicted_class]  # Get class name from class_names list\n",
        "    confidence = predictions[0][predicted_class] * 100  # Get confidence score for the predicted class\n",
        "    return class_label, confidence\n",
        "\n",
        "# Example: Predict on a new image\n",
        "#image_path = '/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/Testing/pituitary/Te-piTr_0000.jpg'  # Replace with the path to the image you want to test\n",
        "predicted_class, confidence = predict_tumor(image_path)\n",
        "print(f\"Predicted Class: {predicted_class} with {confidence:.2f}% confidence.\")\n"
      ],
      "metadata": {
        "id": "VqHIKWrL0_-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/Testing/pituitary/Te-piTr_0004.jpg'  # Replace with the path to the image you want to test\n",
        "predicted_class, confidence = predict_tumor(image_path)\n",
        "print(f\"Predicted Class: {predicted_class} with {confidence:.2f}% confidence.\")\n"
      ],
      "metadata": {
        "id": "XYN0jTo47svR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Step 1: Load the trained model\n",
        "model_path = '/content/drive/MyDrive/Colab Notebooks/Gptmodel/dddriveTUmor.h5'\n",
        "model = load_model(model_path)\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "# Step 2: Set up the test data generator\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "test_datagen = ImageDataGenerator()\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/Testing', # replace with your test folder path\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Step 3: Evaluate the model on the test set to get accuracy and loss\n",
        "evaluation = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {evaluation[0]}\")\n",
        "print(f\"Test Accuracy: {evaluation[1]}\")\n",
        "\n",
        "# Plotting test accuracy as a static single-point plot (since we have no history)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.bar(['Test Accuracy'], [evaluation[1]], color='blue')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Test Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "N_vYDgxE9maN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Step 3: Generate predictions and true labels\n",
        "predictions = model.predict(test_generator)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "# Step 4: Create the confusion matrix\n",
        "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "conf_df = pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels)\n",
        "\n",
        "# Step 5: Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_df, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Step 6: Export confusion matrix to Excel\n",
        "conf_df.to_excel(\"/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/brain_tumor_confusion_matrix.xlsx\")\n",
        "print(\"Confusion matrix saved to Excel.\")"
      ],
      "metadata": {
        "id": "eQgtGP0JBc46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Get class distribution from test data generator\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "class_counts = np.bincount(test_generator.classes)\n",
        "\n",
        "# Step 2: Plot class distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(class_labels, class_counts, color='skyblue')\n",
        "plt.xlabel(\"Class Labels\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.title(\"Class Distribution in Test Set\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Step 3: Export class distribution to Excel\n",
        "class_distribution_df = pd.DataFrame({\n",
        "    \"Class Label\": class_labels,\n",
        "    \"Image Count\": class_counts\n",
        "})\n",
        "\n",
        "excel_path = \"/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/class_distribution.xlsx\"\n",
        "class_distribution_df.to_excel(excel_path, index=False)\n",
        "print(f\"Class distribution saved to Excel at {excel_path}\")\n"
      ],
      "metadata": {
        "id": "t7OBsnYz86Ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Generate predictions\n",
        "y_true = test_generator.classes  # Actual labels from test generator\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert predicted probabilities to class indices\n",
        "\n",
        "# Generate classification report\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "report = classification_report(y_true, y_pred_classes, target_names=class_labels, output_dict=True)\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Display F1 Score, Precision, and Recall for each class\n",
        "print(report_df[['precision', 'recall', 'f1-score']])\n",
        "\n",
        "# Plot F1 score for each class\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=report_df.index[:-3], y=report_df['f1-score'][:-3], palette=\"Blues\")\n",
        "plt.xlabel(\"Class Labels\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "plt.title(\"F1 Score per Class\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Save metrics to Excel\n",
        "excel_path = \"/content/drive/MyDrive/Colab Notebooks/Gptmodel/classification_metrics.xlsx\"\n",
        "report_df.to_excel(excel_path)\n",
        "print(f\"Classification metrics saved to Excel at {excel_path}\")\n"
      ],
      "metadata": {
        "id": "ekf8Kt4vMk9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "excel_path = \"/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/f1classificat_metrics.xlsx\"\n",
        "report_df.to_excel(excel_path)\n",
        "print(f\"Classification metrics saved to Excel at {excel_path}\")"
      ],
      "metadata": {
        "id": "hFs8DLNuUFOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define dataset directory paths\n",
        "train_dir = '/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/Training'\n",
        "test_dir = '/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/Testing'\n",
        "\n",
        "# Initialize lists to collect data\n",
        "data_info = []\n",
        "\n",
        "# Function to collect information\n",
        "def collect_data_info(data_dir, dataset_type):\n",
        "    for class_label in os.listdir(data_dir):\n",
        "        class_path = os.path.join(data_dir, class_label)\n",
        "        if os.path.isdir(class_path):\n",
        "            image_count = len(os.listdir(class_path))\n",
        "            data_info.append({\n",
        "                'Dataset': dataset_type,\n",
        "                'Class Label': class_label,\n",
        "                'Number of Images': image_count\n",
        "            })\n",
        "\n",
        "# Collect data for training and testing sets\n",
        "collect_data_info(train_dir, 'Training')\n",
        "collect_data_info(test_dir, 'Testing')\n",
        "\n",
        "# Convert data to DataFrame and export to Excel\n",
        "data_info_df = pd.DataFrame(data_info)\n",
        "excel_path = \"/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/datacollectiondocumentation.xlsx\"\n",
        "data_info_df.to_excel(excel_path, index=False)\n",
        "\n",
        "print(f\"Data collection information saved to Excel at {excel_path}\")\n"
      ],
      "metadata": {
        "id": "8pGH0S_9RQZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Define directories\n",
        "train_dir = '/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/Training'\n",
        "image_size = (64, 64)  # Resize images to 64x64 to manage data size\n",
        "\n",
        "# Data dictionary to store the preprocessed data\n",
        "data_dict = {\n",
        "    'Dataset': [],\n",
        "    'Class Label': [],\n",
        "    'Image Data': []\n",
        "}\n",
        "\n",
        "# Function to preprocess and add image data to the dictionary\n",
        "def preprocess_and_store_images(data_dir, dataset_type):\n",
        "    for class_label in os.listdir(data_dir):\n",
        "        class_path = os.path.join(data_dir, class_label)\n",
        "        if os.path.isdir(class_path):\n",
        "            for img_name in os.listdir(class_path):\n",
        "                img_path = os.path.join(class_path, img_name)\n",
        "                try:\n",
        "                    # Load, resize, and normalize image\n",
        "                    img = Image.open(img_path).resize(image_size).convert('L')  # Convert to grayscale for simplicity\n",
        "                    img_array = np.array(img) / 255.0  # Normalize pixel values\n",
        "\n",
        "                    # Flatten the image array and store in dictionary\n",
        "                    data_dict['Dataset'].append(dataset_type)\n",
        "                    data_dict['Class Label'].append(class_label)\n",
        "                    data_dict['Image Data'].append(img_array.flatten())  # Flatten for a single row\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Could not process image {img_path}: {e}\")\n",
        "\n",
        "# Preprocess images in training and testing directories\n",
        "preprocess_and_store_images(train_dir, 'Training')\n",
        "\n",
        "# Convert dictionary to DataFrame\n",
        "df = pd.DataFrame(data_dict)\n",
        "\n",
        "# Expand image arrays into separate columns for each pixel\n",
        "image_data_expanded = pd.DataFrame(df['Image Data'].to_list())\n",
        "df = pd.concat([df[['Dataset', 'Class Label']], image_data_expanded], axis=1)\n",
        "\n",
        "# Save preprocessed data to Excel\n",
        "excel_path = '/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/preprocessed_image_data.xlsx'\n",
        "df.to_excel(excel_path, index=False)\n",
        "print(f\"Preprocessed image data saved to Excel at {excel_path}\")\n"
      ],
      "metadata": {
        "id": "W-ISqYmYUwkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load the trained model\n",
        "model_path = '/content/drive/MyDrive/Colab Notebooks/Gptmodel/dddriveTUmor.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Load test data\n",
        "test_dir = '/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/Testing'\n",
        "test_datagen = ImageDataGenerator()\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),  # Adjust this to your image size\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Get the true labels and predicted probabilities\n",
        "true_labels = test_generator.classes\n",
        "predictions = model.predict(test_generator)\n",
        "# Number of classes\n",
        "n_classes = predictions.shape[1]\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(true_labels == i, predictions[:, i]) #Calculate ROC for each class\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
        "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Save ROC data to Excel\n",
        "roc_data = pd.DataFrame({'False Positive Rate': fpr, 'True Positive Rate': tpr})\n",
        "roc_data.to_excel('/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/roc_data.xlsx', index=False)\n",
        "print(\"ROC data saved to Excel.\")\n"
      ],
      "metadata": {
        "id": "PKsjHyL6XboD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "\n",
        "# Iterate through classes and plot ROC curve for each class\n",
        "for i in range(n_classes):\n",
        "    plt.plot(fpr[i], tpr[i], lw=2, label='ROC curve of class {0} (area = {1:.2f})'.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "# Save ROC data to Excel\n",
        "roc_data = pd.DataFrame({'False Positive Rate': fpr, 'True Positive Rate': tpr})\n",
        "roc_data.to_excel('/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1/roc_data.xlsx', index=False)\n",
        "print(\"ROC data saved to Excel.\")"
      ],
      "metadata": {
        "id": "FxeysYwMjdm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ipynbcompress"
      ],
      "metadata": {
        "id": "tCFMXH9vsOfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ipynb-compress Brain_Tumor.ipynb"
      ],
      "metadata": {
        "id": "0tHbpyPrizFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ipynb-compress \"Brain Tumor.ipynb\""
      ],
      "metadata": {
        "id": "id3G6seii6On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "x1jPrjjkkgzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "39dmTvqMkykv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ipynb-compress \"/content/drive/MyDrive/Colab Notebooks/Brain_Tumor.ipynb\""
      ],
      "metadata": {
        "id": "_1aqfweOk7Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nbformat\n",
        "import os\n",
        "\n",
        "# Get the absolute path of the current notebook\n",
        "current_dir = os.getcwd()\n",
        "notebook_filename = os.path.join(current_dir, \"Brain_Tumor.ipynb\")  # Assuming the file is in the same directory\n",
        "\n",
        "# Or specify the full path if it's in a different location:\n",
        "# notebook_filename = \"/path/to/your/notebook/Brain_Tumor.ipynb\"\n",
        "\n",
        "# Load the notebook\n",
        "with open(notebook_filename, \"r\", encoding=\"utf-8\") as f:\n",
        "    nb = nbformat.read(f, as_version=4)\n",
        "# Clear all outputs\n",
        "for cell in nb[\"cells\"]:\n",
        "    if \"outputs\" in cell:\n",
        "        cell[\"outputs\"] = []\n",
        "    if \"execution_count\" in cell:\n",
        "        cell[\"execution_count\"] = None\n",
        "\n",
        "# Save the cleaned notebook\n",
        "compressed_filename = \"Brain_Tumor_Cleaned.ipynb\"\n",
        "with open(compressed_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    nbformat.write(nb, f)\n",
        "\n",
        "print(f\"Compressed notebook saved as {compressed_filename}\")"
      ],
      "metadata": {
        "id": "So9X2c7-ma0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ipynb-compress \"/content/drive/MyDrive/Colab Notebooks/Brain_Tumor.ipynb\""
      ],
      "metadata": {
        "id": "ZwgznbB3m769"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nbconvert"
      ],
      "metadata": {
        "id": "u8xVYXrfnh6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html --ClearOutputPreprocessor.enabled=True \"/content/drive/MyDrive/Colab Notebooks/Brain_Tumor.ipynb\""
      ],
      "metadata": {
        "id": "IXrEAOeAnku_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}